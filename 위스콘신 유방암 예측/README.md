# 🧬 위스콘신 유방암 예측

## 📌 프로젝트 개요
위스콘신 유방암 진단 데이터를 활용하여 다양한 머신러닝 모델을 비교하고,  
전처리 및 하이퍼파라미터 튜닝을 통해 **가장 정확한 예측 모델**을 도출했습니다.  
실제 의료 데이터처럼 불균형한 클래스 분포에서, **정확도뿐 아니라 F1 Score와 AUC**를 고려해 성능을 평가했습니다.

> 📄 전체 보고서 다운로드: [위스콘신_유방암_예측_김나현.docx](./위스콘신_유방암_예측_김나현.docx)

---

## 🧾 데이터 정보
- 출처: UCI 머신러닝 저장소
- 샘플 수: 569개
- 피처 수: 30개 (모두 수치형)
- 타겟 변수: Diagnosis (M = 악성, B = 양성)
- 클래스 분포: 악성 37%, 양성 63% (약간의 불균형)

---

## 🔍 데이터 전처리 전략
- **다중공선성 제거**: 상관계수 0.9 이상 변수 제거
- **왜도 보정**: 로그 변환(np.log1p)
- **표준화**: 평균 0, 표준편차 1 스케일링
- **학습/테스트 분할**: 8:2 비율, `random_state=42`

---

## 🤖 모델 비교 및 결과
| 모델          | Accuracy | F1 Score | AUC    |
|---------------|----------|----------|--------|
| **LightGBM**  | 0.9649   | 0.9726   | —      |
| XGBoost       | 0.9474   | —        | 0.9927 |
| RandomForest  | 0.9561   | —        | —      |
| GradientBoosting | 0.9561 | —        | —      |
| Logistic Reg. | 0.9561   | —        | —      |
| Voting        | 0.9561   | —        | —      |
| KNN / Decision Tree | 낮음 | 낮음 | 낮음 |

---

## 🛠 하이퍼파라미터 튜닝
- `LightGBM`: Hyperopt (→ 성능 유지)
- `RandomForest / GBM`: Grid & Random Search (→ 변화 거의 없음)
- `XGBoost`: Hyperopt → 모든 지표 개선

---

## 💡 인사이트 및 적용 방안
- `LightGBM`은 튜닝 전에도 높은 성능 → **강력한 베이스라인 모델**
- `XGBoost`는 **민감도 중심 문제 (AUC 우선)**에서 더 적합
- 다양한 모델을 비교하는 과정 자체가 실무 적용 판단에 큰 도움
- 단순 Accuracy만이 아닌 **F1 Score, AUC 등 다면적 평가 지표 고려가 필수**

---

## 🙋🏻‍♀️ 프로젝트 수행 범위
본 프로젝트는 데이터 분석, 전처리 설계, 모델링, 튜닝, 시각화, 문서화까지  
**모든 과정을 개인 단독으로 수행**하였습니다.
